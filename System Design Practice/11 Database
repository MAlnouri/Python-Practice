relation database like SQL is a collection of data items organized in tables
ACID is a set of properties of relation database transactions
    Atomicity - each transaction is all or nothing
    Consistency - any transaction will bring the database from one valid state to another
    Isolation - executing transactions concurrently has the same results as if the transactions were executed serially
    Durability - once a transaction has been committed, it will remain so

there are amny techniques to scale relational db
- master-slave replication
    master reads/writes, replicates to slaves which only read
    slaves can also replicate in tree like fashion
    if master goes offline, can still operate read only mode until slave is promoted to master
    disadvantages: additional logic needed to promote slave to master

- master-master replication
    both masters read, write and replicate to each other
    if either master goes down, the other continues operations
    disadvantages:
        need lb or logic to pick which to write to
        moster master-master systems are loosely consistent(violate ACID) or have increased write latency due to synchronization
        conflict resolution comes more into play as more write nodes are added and as latency increases

    other disadvantages for replication:
        potential loss of data if master fails before new data can be replicated
        writes are replayed on read replicas, this can slow down reads if there are too many writes being replicated
        more read slaves = more replication = greater replication lag
        on some systems, writing to master can spawn multiple threads to write in parallel, where read replicas only support writing sequentially with a single thread
        replication adds more hardware and complexity

- federation
    federation (or functional partitioning) splits up dbs by function
    ex: instead of single monolithic db, have 3 dbs: forums, users, products
        results in less read and write traffic to each db, therefore less replication lag
        smaller dbs result in more data that can fit in memory, which results in more cache hits due to improved cache locality
        no single central master serializing writes means you can write in parallel, increasing throughput
    disadvantages:
        federation is not effective if your schema requires huge functions or tables
        you need to update your application logic to pick which db to read and write
        joining data from 2 dbs is more complex with a server link
        federation adds more hardware and complexity

- sharding
    sharding distributes data across different dbs such that each db can only manage a subset of data
    ex: a users db, as # of users increases, more shards are added to cluster
    similar to federation, sharding results in less read/write traffic, less replication, more cache hits
    index size is also reduced, generally improves performance with faster queries
    if 1 shard goes down, other shards still operational, but should add replication to avoid data loss
    no single central master serializing writes, allows you to write in parallel with increased throughput
    
    common ways to shard a table of users is through users last name initial or users geo location

    disadvantages:
        you need to update application logic to work with shards, could result in complex SQL queries
        data distribution can become lopsided in a shard
        - ex: set of power users on a shard could result in increased load to that shard
            rebalancing adds complexity, sharding function based on consistent hashing can reduce amount of transferred data
        joining data from multiple shards is more complex
        sharding adds more hardware and complexity

- denormalization
    denorm attempts to improve read perf at expense of some write perf
    redundant copies of data are written in multiple tables to avoid expensive joins
    some rdbms like PostgreSQL and Oracle support materialized views which handle the work of storing redundant info and keeping redundant copies consistent

    once data becomes distributed w/ techniques such as federation/sharding, managing joins across data centers further increases complexity
    denorm might circumvent need for such complex joins

    in most systems, reads can heavily outnumber writes 100:1 or even 1000:1
    read resulting in a complex db join can be expensive, spending significant amount of time on disk operations

    disadvantages:
        data is duplicated
        constraints can help redundant copies of info stay in sync, which increases complexity of db design
        denorm db under heavy write load might perform worse than normalized version of the db

- SQL tuning
    